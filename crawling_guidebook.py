import time
import sys
from dotenv import load_dotenv
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from langchain_community.document_loaders import PlaywrightURLLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼ ì½ê¸°)
load_dotenv()

# ì„¤ì •ê°’
INDEX_NAME = "aion2-guide-rag"  # Pinecone ì½˜ì†”ì—ì„œ ë¯¸ë¦¬ ë§Œë“¤ì–´ë‘” ì¸ë±ìŠ¤ ì´ë¦„ê³¼ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.

def collect_nc_guide_urls(start_id, end_id):
    print(f"ğŸš€ ìˆ˜ì§‘ ì‹œì‘: CategoryId {start_id} ~ {end_id}")

    options = webdriver.ChromeOptions()
    # options.add_argument('--headless') # ì˜ ë˜ëŠ”ê±° í™•ì¸í•˜ì‹œë©´ ì£¼ì„ í•´ì œí•˜ì„¸ìš” (ì†ë„ í–¥ìƒ)
    options.add_argument("--window-size=1920,1080")
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    
    all_urls = set()

    try:
        for cat_id in range(start_id, end_id + 1):
            url = f"https://aion2.plaync.com/ko-kr/guidebook/list#categoryId={cat_id}"
            print(f"\nğŸ”„ [Category {cat_id}] ì´ë™ ì¤‘...")
            
            driver.get(url)

            try:
                # 1. ëª…í™•í•œ í´ë˜ìŠ¤ëª…ì´ ë¡œë”©ë  ë•Œê¹Œì§€ ëŒ€ê¸°
                wait = WebDriverWait(driver, 10)
                target_class = "ncgbg-guide-depth-2-guide-item-link"
                
                wait.until(EC.presence_of_element_located((By.CLASS_NAME, target_class)))
                time.sleep(1) # ë Œë”ë§ ì•ˆì •í™”

                # 2. í•´ë‹¹ í´ë˜ìŠ¤ë¥¼ ê°€ì§„ ëª¨ë“  ìš”ì†Œë¥¼ ì°¾ìŒ
                elements = driver.find_elements(By.CLASS_NAME, target_class)
                
                count = 0
                for el in elements:
                    # Seleniumì´ hrefë¥¼ ê°€ì ¸ì˜¬ ë•Œ ìë™ìœ¼ë¡œ http://... ì „ì²´ ê²½ë¡œë¡œ ë³€í™˜í•´ì¤ë‹ˆë‹¤.
                    full_url = el.get_attribute("href")
                    
                    # ê°€ë” ë¹ˆ ë§í¬ë‚˜ ì¤‘ë³µì´ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ í•„í„°ë§
                    if full_url and "view?title=" in full_url:
                        all_urls.add(full_url)
                        count += 1
                
                print(f"   âœ… {count}ê°œ ìˆ˜ì§‘ ì„±ê³µ")

            except Exception:
                print(f"   âš ï¸ [Category {cat_id}] í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì— ê¸€ì´ ì—†ê±°ë‚˜ ë¡œë”© ì‹¤íŒ¨")
                continue

    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
    
    finally:
        driver.quit()

    return list(all_urls)

# --- ì‹¤í–‰ ---

    # 4234 ~ 4244 ì „ì²´ ìˆ˜ì§‘
final_urls = collect_nc_guide_urls(4234, 4244)

print(f"\nğŸ‰ ìµœì¢… ìˆ˜ì§‘ ê²°ê³¼: ì´ {len(final_urls)}ê°œ")
for url in final_urls:
    print(url)

def load_split_docs(final_urls):
    print("1. ë°ì´í„° ë¡œë”© ì¤‘... (Playwright ì‚¬ìš©)")
    
    # PlaywrightURLLoader ì„¤ì •
    loader = PlaywrightURLLoader(
        urls=final_urls,
        remove_selectors=["nav", "header", "footer", ".cookie-banner"], # ë¶ˆí•„ìš”í•œ UI ì œê±°
        continue_on_failure=True
    )

    try:
        # ì‹¤ì œ ë¸Œë¼ìš°ì €ë¥¼ ë„ì›Œ ë Œë”ë§ í›„ ë¡œë”©
        docs = loader.load()
        
        print(f"-> ë¡œë“œëœ ë¬¸ì„œ ê°œìˆ˜: {len(docs)}")
        if docs:
            # ì²« ë²ˆì§¸ ë¬¸ì„œ ë‚´ìš© ì•ë¶€ë¶„ë§Œ ì¶œë ¥í•´ì„œ ì œëŒ€ë¡œ ê¸ì–´ì™”ëŠ”ì§€ í™•ì¸
            print(f"\n[ì²« ë²ˆì§¸ ë¬¸ì„œ ìƒ˜í”Œ]\n{docs[0].page_content[:300]}...\n")
            
        print("2. í…ìŠ¤íŠ¸ ë¶„í•  ì¤‘...")
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )

        splits = text_splitter.split_documents(docs)
        print(f"-> ì´ ë¶„í• ëœ ì²­í¬ ìˆ˜: {len(splits)}")
        for split in splits:
            print(split.page_content)
        
        # # TODO: ì—¬ê¸°ì„œ Pinecone ì €ì¥ ë¡œì§ ìˆ˜í–‰
        # # 3. ì„ë² ë”© ë° Pinecone ì €ì¥
        # print(f"3. Pinecone('{INDEX_NAME}')ì— ë°ì´í„° ì €ì¥ ì‹œì‘...")
        
        # embeddings = OpenAIEmbeddings(model="text-embedding-3-small") # ìµœì‹  ëª¨ë¸ ì‚¬ìš© ê¶Œì¥

        # # Pineconeì— ë¬¸ì„œ ì—…ë¡œë“œ (Batchë¡œ ìë™ ì²˜ë¦¬ë¨)
        # vectorstore = PineconeVectorStore.from_documents(
        #     documents=splits,
        #     embedding=embeddings,
        #     index_name=INDEX_NAME
        # )
        
        print("ğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    except Exception as e:
        print(f"ì—ëŸ¬ ë°œìƒ: {e}")

load_split_docs(final_urls)