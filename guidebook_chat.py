import streamlit as st
from guidebook_rag import get_rag_chain # ë¶„ë¦¬í•œ íŒŒì¼ import

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="AION2 ê°€ì´ë“œ ë´‡", page_icon="ğŸ›¡ï¸")

# === Helper Function: ì±„íŒ… ì´ë ¥ í¬ë§·íŒ… ===
def format_chat_history(messages):
    """
    Streamlit ì„¸ì…˜ì˜ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ LLMì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ìµœê·¼ 5í„´(10ê°œ ë©”ì‹œì§€)ë§Œ ìœ ì§€í•˜ì—¬ í† í°ì„ ì ˆì•½í•©ë‹ˆë‹¤.
    """
    formatted_history = []
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì œì™¸í•˜ê³  ìµœê·¼ ëŒ€í™”ë§Œ ê°€ì ¸ì˜¤ê¸°
    recent_messages = messages[-10:] 
    
    for msg in recent_messages:
        role = "User" if msg["role"] == "user" else "AI"
        content = msg["content"]
        formatted_history.append(f"{role}: {content}")
        
    return "\n".join(formatted_history)

# === Main UI ===
st.title("ğŸ›¡ï¸ AION2 ê²Œì„ ê°€ì´ë“œ (Context)")

# 1. ì²´ì¸ ë¡œë”© (ìºì‹±)
@st.cache_resource
def load_chain():
    return get_rag_chain()

chain = load_chain()

# 2. ì„¸ì…˜ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# 3. ëŒ€í™” ê¸°ë¡ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "sources" in message:
            with st.expander("ğŸ“š ì°¸ê³  ë¬¸ì„œ"):
                for src in message["sources"]:
                    st.markdown(f"- **{src['title']}** ({src['score']:.2f})")

# 4. ì…ë ¥ ì²˜ë¦¬
if query := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ ë° ì €ì¥
    st.chat_message("user").write(query)
    st.session_state.messages.append({"role": "user", "content": query})

    if chain:
        with st.chat_message("assistant"):
            container = st.empty()
            container.markdown("â³ ìƒê° ì¤‘...")
            
            # [í•µì‹¬] í˜„ì¬ ì±„íŒ… ì´ë ¥ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
            chat_history_str = format_chat_history(st.session_state.messages[:-1])
            
            try:
                # [í•µì‹¬] ì§ˆë¬¸ê³¼ íˆìŠ¤í† ë¦¬ë¥¼ í•¨ê»˜ ì „ë‹¬
                result = chain.invoke({
                    "question": query,
                    "chat_history": chat_history_str
                })
                
                answer = result['answer']
                sources = result['context']
                
                container.markdown(answer)
                
                # ì¶œì²˜ UI ìƒì„±
                source_data = []
                with st.expander("ğŸ“š ì°¸ê³  ë¬¸ì„œ í™•ì¸"):
                    for doc in sources:
                        score = doc.metadata.get('relevance_score', 0)
                        title = doc.metadata.get('title', 'ì œëª© ì—†ìŒ')
                        source_data.append({"title": title, "score": score})
                        st.markdown(f"**[{title}]** ({score:.2f})")
                        st.caption(doc.page_content[:100] + "...")

                # AI ì‘ë‹µ ì €ì¥
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": answer,
                    "sources": source_data
                })
                
            except Exception as e:
                container.error(f"ì—ëŸ¬ ë°œìƒ: {e}")